# Progress Report

## November 21, 2017
- data collection (for the last time)
- updated all of the "statistics" throughout, since I'm done collecting data (it hasn't changed much over the past few updates) I will not need to re-update these until I gather more data again
- did a bunch of small stuff to make things read better and work better- made the bar plots
- started work on figuring out the most popular hashtag (popular meaning most commonly used with the highest amount of retweets/favorites)

## November 17, 2017
- data collection
- got all of the most popular tweet locations, but need to figure out a better way to display them

## November 15, 2017
- data collection
- started work on where the most popular tweets are.
- cats have progressively gained in popularity.

## November 12, 2017
- more data collection

## November 10, 2017
- continued data collection

## November 6, 2017
- more data collection
- creation of pie charts and a few more bar plots.
- interesting changes noted. cats suddenly gained a lot in popularity, but not in number. What happened?

## November 5, 2017
- more data collection.
- interesting results that essentially flipped everything around, very interesting.

## November 2, 2017
- It won't let me commit my jupyter notebook file, but everything else seems to be committing fine, so I'll just have to figure that out soon. (fixed)
- Still trying to figure out how to know if the tweet contains a photo or not?
- suddenly having issues with the 'cat_tweets.csv' file, but the dog file is fine. I'll see what I can do there.
- finished the bar graph and then started working with location, but it went weird so I decided to try looking at it again a little later.
- added timezone information
- realized a big issue and I have to restart my data storing, I was wondering why I was having so many issues... I forgot about the fact that tweets themselves can have a lot of special characters in them... commas included and that is screwing with everything... I think that the problem is really only in the twitter post itself and the bios. (people like to format fancy) so the easiest way to add in token count to my df and if needed restore tweets by ID # later.

## November 1, 2017  
- fixed the committing issue.
- added a lot more to the code.
- haven't really started analysis yet, I really haven't had the time. Did a lot of cleaning with the data.
- added to the dataset file on my local drive.
- changed the counter to just the mean of the row and added in retweets
- Question that has risen: if I'm not allowed to share anything but the ID, what is okay to be shown code-wise in my jupyter notebook?

## October 29, 2017  
- found out I'm having issues committing changes to GitHub? None of my changes since the first progress report have been committed.
- Added more tweets to dataset
- made favorite counter

## October 28, 2017  
- updated the project plan to have data sharing after figuring out the licensing stuff, finally.
- I also added in the stuff about plurality that Narae mentioned because it is unclear how Twitter handles plurals

## October 22, 2017
-  I made a few improvements on existing code. I stored some more tweets to get a bigger corpus.
- Still having computer trouble
- Added tweets to dataset

## October 21, 2017  
- added more tweets to the dataset
- I didn't have my computer for a while so progress until now was static.

## October 16, 2017  
- Added a bit
- Started storing Tweets so that I can have a larger dataset

## October 12, 2017
- Regenerated the tokens and now things are finally working!

## October 11, 2017
- Nope, that's it. I'm changing everything
- Cats vs. Dogs, let's go.
- Cannot get authentication working at all????

## October 10, 2017
- The BSL data looked like it was accessible but it is actually only accessible in the UK.
- Trying to get this data seems harder than expected, and the ASL corpus is completely inaccurate?
